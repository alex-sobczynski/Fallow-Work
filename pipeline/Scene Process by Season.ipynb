{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############################\n",
    "##### LOAD LIBRARIES #######\n",
    "############################\n",
    "\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Proj, transform\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############################\n",
    "###### LOCATION SPECS ######\n",
    "############################\n",
    "\n",
    "# path and row should change for each iteration\n",
    "path = 170\n",
    "row_name = '064'\n",
    "path_row = \"170064\"\n",
    "#wd = \"C:/Users/asobc/PycharmProjects/fallow/\"\n",
    "wd = \"D:/\"\n",
    "#folder_name = f'{path}_{row_name}_raw/'\n",
    "folder_name = f'{path}_{row_name}_raw/'\n",
    "folder_path = os.path.join(wd, folder_name)\n",
    "plant_time = [\"02\",\"03\"]\n",
    "grow_time = [\"04\",\"05\",\"06\"]\n",
    "growing_mid_month = '06'\n",
    "growing_mid_day = '15'\n",
    "planting_mid_month = '02'\n",
    "planting_mid_day = '15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############################\n",
    "##### DEFINE FUNCTIONS #####\n",
    "############################\n",
    "\n",
    "# extracting date from file name\n",
    "def extract_date(filename):\n",
    "    return filename[17:25]\n",
    "\n",
    "# converting utm to lon and lat\n",
    "def utm_to_latlon(row, east_name, north_name, zone_number):\n",
    "    easting = row[east_name]\n",
    "    northing = row[north_name]\n",
    "\n",
    "    utm_proj = Proj(proj='utm', zone=zone_number, ellps='WGS84', datum='WGS84')\n",
    "\n",
    "    lon, lat = utm_proj(easting, northing, inverse=True)\n",
    "\n",
    "    return pd.Series({'lat': lat, 'lon': lon})\n",
    "# converting lon and lat to utm\n",
    "def latlon_to_utm(longitude, latitude, zone_number):\n",
    "    utm_proj = Proj(proj='utm', zone=zone_number, ellps='WGS84', datum='WGS84')\n",
    "\n",
    "    easting, northing = utm_proj(longitude, latitude)\n",
    "\n",
    "    return easting, northing\n",
    "\n",
    "# getting the utm zone code out of the .xml file\n",
    "def extract_utm_zone(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    zone_tag = root.find('.//{http://espa.cr.usgs.gov/v2}zone_code')\n",
    "\n",
    "    if zone_tag is not None:\n",
    "        zone_code = zone_tag.text.strip()\n",
    "        return zone_code\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# getting the utm zone code out of the .xml file\n",
    "def extract_scene_coords(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    corner_coordinates = {}\n",
    "\n",
    "    for corner_point in root.findall('.//{http://espa.cr.usgs.gov/v2}corner_point'):\n",
    "        location = corner_point.get('location')\n",
    "        x = float(corner_point.get('x'))\n",
    "        y = float(corner_point.get('y'))\n",
    "        corner_coordinates[location + '_x'] = x\n",
    "        corner_coordinates[location + '_y'] = y\n",
    "\n",
    "    return corner_coordinates\n",
    "\n",
    "# trimming the raster\n",
    "# REVISIT\n",
    "# Commented areas are for plotting the raster\n",
    "def trim_raster(raster_file, trim_box, output_folder, note, season):\n",
    "    with rasterio.open(raster_file) as src:\n",
    "        window = src.window(*trim_box)\n",
    "        data = src.read(window=window)\n",
    "        #bounds = src.window_bounds(window)\n",
    "        #lon, lat = np.meshgrid(np.linspace(bounds[0], bounds[2], data.shape[2]),\n",
    "        #                       np.linspace(bounds[1], bounds[3], data.shape[1]))\n",
    "\n",
    "        transform = src.window_transform(window)\n",
    "\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            'transform': transform,\n",
    "            'height': window.height,\n",
    "            'width': window.width\n",
    "        })\n",
    "        output_file = os.path.join(output_folder,os.path.basename(raster_file)[:-4] + f'_{season}_{note}_TRIM.tif')\n",
    "\n",
    "        # Write the trimmed raster to the output file\n",
    "        with rasterio.open(output_file, 'w', **meta) as dst:\n",
    "            dst.write(data)\n",
    "\n",
    "    pass\n",
    "\n",
    "    # plt.imshow(data.squeeze(), cmap='jet', extent = [lon.min(), lon.max(), lat.min(), lat.max()])\n",
    "    # plt.title('Zoomed in Bounding Box')\n",
    "    # plt.xlabel('lon (meters)')\n",
    "    # plt.ylabel('lat (meters)')\n",
    "    # plt.colorbar(label='EVI')\n",
    "    # plt.show()\n",
    "\n",
    "# converting trimmed rasters to csvs\n",
    "def raster_to_csv(raster_file, quality_file, east_name, north_name, zone_number, output_folder):\n",
    "\n",
    "    with rasterio.open(raster_file) as src:\n",
    "        raster_array = src.read(1)\n",
    "        nodata_value = src.nodata\n",
    "        raster_array = np.where(raster_array == nodata_value, np.nan, raster_array)\n",
    "        transform = src.transform\n",
    "\n",
    "        rows, cols = raster_array.shape\n",
    "        X, Y = np.meshgrid(np.arange(0, cols), np.arange(0, rows))\n",
    "        east, north = transform * (X, Y)\n",
    "\n",
    "        flat_east = east.flatten()\n",
    "        flat_north = north.flatten()\n",
    "        flat_data = raster_array.flatten()\n",
    "\n",
    "        evi = pd.DataFrame({\n",
    "            'easting': flat_east,\n",
    "            'northing': flat_north,\n",
    "            'evi': flat_data\n",
    "        })\n",
    "    with rasterio.open(quality_file) as src:\n",
    "        quality_array = src.read(1)\n",
    "\n",
    "        nodata_value = src.nodata\n",
    "        quality_array = np.where(quality_array == nodata_value, np.nan, quality_array)\n",
    "        transform = src.transform\n",
    "        rows, cols = quality_array.shape\n",
    "        X_q, Y_q = np.meshgrid(np.arange(0, cols), np.arange(0, rows))\n",
    "\n",
    "        east_q, north_q = transform * (X_q, Y_q)\n",
    "\n",
    "        flat_east_q = east_q.flatten()\n",
    "        flat_north_q = north_q.flatten()\n",
    "        flat_data_q = quality_array.flatten()\n",
    "\n",
    "        qual = pd.DataFrame({\n",
    "            'easting': flat_east_q,\n",
    "            'northing': flat_north_q,\n",
    "            'quality': flat_data_q\n",
    "        })\n",
    "\n",
    "    df = pd.merge(evi, qual, on=['easting', 'northing'])\n",
    "\n",
    "    del evi\n",
    "    del qual\n",
    "    df[['latitude', 'longitude']] = df.apply(utm_to_latlon, axis=1, args=(east_name, north_name, zone_number))\n",
    "\n",
    "    output_file = os.path.join(output_folder,os.path.basename(raster_file)[:-11] + '.csv')\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "###### EXTRACT FILES ######\n",
    "###########################\n",
    "\n",
    "def extract_specific_files(file_path, destination, evi, quality, xml):\n",
    "    with tarfile.open(file_path, 'r:gz') as tar:\n",
    "        # tar.extractall(destination)\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith(evi) or member.name.endswith(quality) or member.name.endswith(xml):\n",
    "                member.name = os.path.basename(member.name)\n",
    "                path = os.path.join(destination, member.name)\n",
    "                if os.path.exists(path):\n",
    "                    continue\n",
    "                else:\n",
    "                    tar.extract(member, destination)\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "    pass\n",
    "for file in os.listdir(folder_path):\n",
    "    name, ext = os.path.splitext(file)\n",
    "    if ext == \".gz\":\n",
    "        file_name = name\n",
    "        ext = ext\n",
    "        extract_specific_files(f'{folder_path}{file_name}{ext}', folder_path, \"_SR_EVI.tif\",\"_QA_PIXEL.tif\", \"T1.xml\")\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "##### FILE DATAFRAME #####\n",
    "##########################\n",
    "\n",
    "file_data = {}\n",
    "for filename in os.listdir(folder_path):\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    date = extract_date(name)\n",
    "    # Check if the file is a TIFF file\n",
    "    if ext == \".tif\" and 'EVI' in name:\n",
    "        file_type = \"evi\"\n",
    "    elif ext == \".tif\" and 'PIXEL' in name:\n",
    "        file_type = \"quality\"\n",
    "    elif ext == \".xml\" and 'MTL' not in name:\n",
    "        file_type = \"xml\"\n",
    "    else:\n",
    "        continue  # Skip files of other types\n",
    "    if date in file_data:\n",
    "        file_data[date][file_type] = filename\n",
    "    else:\n",
    "        file_data[date] = {file_type: filename}\n",
    "\n",
    "scene_specs = pd.DataFrame(file_data).transpose()\n",
    "#print(scene_specs.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "##### SCENE SPECS #####\n",
    "#######################\n",
    "\n",
    "scene_specs['zone_number'] = \"\"\n",
    "scene_specs['upper_left_x'] = \"\"\n",
    "scene_specs['upper_left_y'] = \"\"\n",
    "scene_specs['lower_right_x'] = \"\"\n",
    "scene_specs['lower_right_y'] = \"\"\n",
    "scene_specs['satellite'] = \"\"\n",
    "scene_specs['year'] = \"\"\n",
    "scene_specs['month'] = \"\"\n",
    "scene_specs['day'] = \"\"\n",
    "scene_specs['season'] = \"\"\n",
    "scene_specs['target_date'] = \"\"\n",
    "\n",
    "for index, row in scene_specs.iterrows():\n",
    "    xml_file = row['xml']\n",
    "    zone_number = extract_utm_zone(os.path.join(folder_path, xml_file))\n",
    "    corner_coordinates = extract_scene_coords(os.path.join(folder_path, xml_file))\n",
    "    scene_specs.at[index,'zone_number'] = zone_number\n",
    "    scene_specs.at[index,'upper_left_x'] = corner_coordinates.get('UL_x')\n",
    "    scene_specs.at[index,'upper_left_y'] = corner_coordinates.get('UL_y')\n",
    "    scene_specs.at[index,'lower_right_x'] = corner_coordinates.get('LR_x')\n",
    "    scene_specs.at[index,'lower_right_y'] = corner_coordinates.get('LR_y')\n",
    "    scene_specs.at[index,'satellite'] = row['xml'][3:4]\n",
    "    scene_specs.at[index,'year'] = row['xml'][17:21]\n",
    "    scene_specs.at[index,'month'] = row['xml'][21:23]\n",
    "    scene_specs.at[index,'day'] = row['xml'][23:25]\n",
    "    if scene_specs.at[index, 'month'] in grow_time:\n",
    "        scene_specs.at[index,'season'] = \"gro\"\n",
    "    elif scene_specs.at[index, 'month'] in plant_time:\n",
    "        scene_specs.at[index,'season'] = \"sow\"\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "scene_specs['date'] = pd.to_datetime(scene_specs['year'] + scene_specs['month'] + scene_specs['day'], format='%Y%m%d')\n",
    "\n",
    "for index, row in scene_specs.iterrows():\n",
    "    if scene_specs.at[index, 'season'] == \"gro\":\n",
    "        scene_specs.at[index,'target_date'] = pd.to_datetime(row['year'] + f'-{growing_mid_month}-{growing_mid_day}')\n",
    "    elif scene_specs.at[index, 'season'] == \"sow\":\n",
    "        scene_specs.at[index,'target_date'] = pd.to_datetime(row['year'] + f'-{planting_mid_month}-{planting_mid_day}')\n",
    "\n",
    "scene_specs['target_date'] = pd.to_datetime(scene_specs['target_date'])\n",
    "scene_specs['days_from_target'] = (scene_specs['target_date'] - scene_specs['date']).dt.days.abs()\n",
    "scene_specs.drop(columns=['target_date'], inplace=True)\n",
    "\n",
    "print(scene_specs.head(4))\n",
    "print(scene_specs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "## FIND AVERAGE BOUNDING BOX ##\n",
    "###############################\n",
    "\n",
    "seven_scenes = scene_specs[(scene_specs['satellite'] == '7') & (scene_specs['season'] == 'gro')]\n",
    "\n",
    "med_east = seven_scenes['upper_left_x'].median()\n",
    "\n",
    "seven_scenes['diff_from_median'] = abs(seven_scenes['upper_left_x'] - med_east)\n",
    "sorted_seven = seven_scenes.sort_values(by='diff_from_median')\n",
    "top_5_rows = sorted_seven.head(5)#.copy()\n",
    "\n",
    "med_north = top_5_rows['upper_left_y'].median()\n",
    "med_scenes = top_5_rows[top_5_rows['upper_left_y'] == med_north]\n",
    "\n",
    "row_index = med_scenes.index[0]\n",
    "med_scene = top_5_rows.loc[row_index]#.copy()\n",
    "easting1 = (med_scene['upper_left_x'] + med_scene['lower_right_x'])/2 - 6000\n",
    "easting2 = (med_scene['upper_left_x'] + med_scene['lower_right_x'])/2 + 6000\n",
    "northing1 = (med_scene['upper_left_y'] + med_scene['lower_right_y'])/2 - 6000\n",
    "northing2 = (med_scene['upper_left_y'] + med_scene['lower_right_y'])/2 + 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "### LOAD AND CLIP RASTERS ###\n",
    "#############################\n",
    "\n",
    "# the note indicates which bounding box the trimmed .tif is from.\n",
    "# ss is the furthest south, ms is middle south, mm is middle, mn is middle north, and nn is furthest north and all are along the central landsat axis\n",
    "# the slope of the central axis in my test scene was approximately 4.63, so this is the ratio I use\n",
    "\n",
    "output_folder = f\"trimmed_{path}_{row_name}\"\n",
    "output_joined = os.path.join(wd, output_folder)\n",
    "print(output_joined)\n",
    "os.makedirs(output_joined, exist_ok=True)\n",
    "\n",
    "trim_boxes = {\n",
    "    'ss': (easting1 - 12000, northing1 - 55560, easting2 - 12000, northing2 - 55560),\n",
    "    'ms': (easting1 - 6000, northing1 - 27780, easting2 - 6000, northing2 - 27780),\n",
    "    'mm': (easting1, northing1, easting2, northing2),\n",
    "    'mn': (easting1 + 6000, northing1 + 27780, easting2 + 6000, northing2 + 27780),\n",
    "    'nn': (easting1 + 12000, northing1 + 55560, easting2 + 12000, northing2 + 55560)\n",
    "}\n",
    "\n",
    "loc_list = ['ss','ms','mm','mn','nn']\n",
    "for i in loc_list:\n",
    "    trim_box = trim_boxes[i]\n",
    "    for index, row in scene_specs.iterrows():\n",
    "        raster_name = row['evi']\n",
    "        raster_file = os.path.join(folder_path, raster_name)\n",
    "        season = row['season']\n",
    "        trim_raster(raster_file, trim_box, output_joined, i, season)\n",
    "\n",
    "    for index, row in scene_specs.iterrows():\n",
    "        raster_name = row['quality']\n",
    "        raster_file = os.path.join(folder_path, raster_name)\n",
    "        season = row['season']\n",
    "        trim_raster(raster_file, trim_box, output_joined, i, season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############################\n",
    "###### RASTER TO CSV #######\n",
    "############################\n",
    "\n",
    "# commented out pieces are for the lon/lat conversion which I will be putting off for this piece\n",
    "\n",
    "def raster_to_csv(raster_file, quality_file,\n",
    "                  #east_name, north_name, zone_number,\n",
    "                  output_joined, id, sat, location, season):\n",
    "\n",
    "    with rasterio.open(raster_file) as src:\n",
    "        raster_array = src.read(1)\n",
    "        nodata_value = src.nodata\n",
    "        raster_array = np.where(raster_array == nodata_value, np.nan, raster_array)\n",
    "        transform = src.transform\n",
    "\n",
    "        rows, cols = raster_array.shape\n",
    "        X, Y = np.meshgrid(np.arange(0, cols), np.arange(0, rows))\n",
    "        east, north = transform * (X, Y)\n",
    "\n",
    "        flat_east = east.flatten()\n",
    "        flat_north = north.flatten()\n",
    "        flat_data = raster_array.flatten()\n",
    "\n",
    "        evi = pd.DataFrame({\n",
    "            'easting': flat_east,\n",
    "            'northing': flat_north,\n",
    "            'evi': flat_data\n",
    "        })\n",
    "    with rasterio.open(quality_file) as src:\n",
    "        quality_array = src.read(1)\n",
    "\n",
    "        nodata_value = src.nodata\n",
    "        quality_array = np.where(quality_array == nodata_value, np.nan, quality_array)\n",
    "        transform = src.transform\n",
    "        rows, cols = quality_array.shape\n",
    "        X_q, Y_q = np.meshgrid(np.arange(0, cols), np.arange(0, rows))\n",
    "\n",
    "        east_q, north_q = transform * (X_q, Y_q)\n",
    "\n",
    "        flat_east_q = east_q.flatten()\n",
    "        flat_north_q = north_q.flatten()\n",
    "        flat_data_q = quality_array.flatten()\n",
    "\n",
    "        qual = pd.DataFrame({\n",
    "            'easting': flat_east_q,\n",
    "            'northing': flat_north_q,\n",
    "            'quality': flat_data_q\n",
    "        })\n",
    "\n",
    "    df = pd.merge(evi, qual, on=['easting', 'northing'])\n",
    "\n",
    "    del evi\n",
    "    del qual\n",
    "\n",
    "    #df[['latitude', 'longitude']] = df.apply(utm_to_latlon, axis=1, args=(east_name, north_name, zone_number))\n",
    "\n",
    "    # I don't actually need to generate csvs to evaluate, so will probably cut this in the future\n",
    "\n",
    "    output_file = os.path.join(output_joined,os.path.basename(raster_file)[:-23] + f'{location}.csv')\n",
    "    #df.to_csv(output_file, index=False)\n",
    "\n",
    "    size = df.shape[0]\n",
    "    qual_counts = df['quality'].value_counts()\n",
    "\n",
    "    index = qual_counts.index.to_numpy()\n",
    "    values = qual_counts.to_numpy()\n",
    "    qual_sum = pd.DataFrame({'quality': index, 'count': values})\n",
    "    qual_sum['date'] = id\n",
    "    qual_sum['satellite'] = sat\n",
    "    qual_sum['length'] = size\n",
    "    qual_sum['season'] = season\n",
    "    qual_sum['trim_file_evi'] = os.path.basename(raster_file)\n",
    "    qual_sum['trim_file_qual'] = os.path.basename(quality_file)\n",
    "    return qual_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "### QUALITY LIST TO DATAFRAME ###\n",
    "#################################\n",
    "\n",
    "output_folder = f\"trimmed_{path}_{row_name}\"\n",
    "output_joined = os.path.join(wd, output_folder)\n",
    "\n",
    "list_mm = []\n",
    "list_nn = []\n",
    "list_ms = []\n",
    "list_mn = []\n",
    "list_ss = []\n",
    "\n",
    "loc_list = ['nn','mm','ms','mn','ss']\n",
    "\n",
    "for i in loc_list:\n",
    "    #qual_list = []\n",
    "    for index, row in scene_specs[scene_specs['season'] == 'gro'].iterrows():\n",
    "        raster_name = row['evi']\n",
    "        quality_name = row['quality']\n",
    "        season = row['season']\n",
    "        raster_file = os.path.join(output_joined, raster_name[:-4] + f'_{season}_{i}_TRIM.tif')\n",
    "        quality_file = os.path.join(output_joined, quality_name[:-4] + f'_{season}_{i}_TRIM.tif')\n",
    "        #zone_number = row['zone_number']\n",
    "        #east_name = 'easting'\n",
    "        #north_name = 'northing'\n",
    "        id = index\n",
    "        sat = row['satellite']\n",
    "        location = i\n",
    "        gro_df = raster_to_csv(raster_file, quality_file,\n",
    "                                #east_name, north_name, zone_number,\n",
    "                                output_joined, id, sat, location, season)\n",
    "        if i == 'mm':\n",
    "            list_mm.append(gro_df)\n",
    "        elif i == 'nn':\n",
    "            list_nn.append(gro_df)\n",
    "        elif i == 'ms':\n",
    "            list_ms.append(gro_df)\n",
    "        elif i == 'mn':\n",
    "            list_mn.append(gro_df)\n",
    "        elif i == 'ss':\n",
    "            list_ss.append(gro_df)\n",
    "\n",
    "for i in loc_list:\n",
    "    #qual_list = []\n",
    "    for index, row in scene_specs[scene_specs['season'] == 'sow'].iterrows():\n",
    "        raster_name = row['evi']\n",
    "        quality_name = row['quality']\n",
    "        season = row['season']\n",
    "        raster_file = os.path.join(output_joined, raster_name[:-4] + f'_{season}_{i}_TRIM.tif')\n",
    "        quality_file = os.path.join(output_joined, quality_name[:-4] + f'_{season}_{i}_TRIM.tif')\n",
    "        #zone_number = row['zone_number']\n",
    "        #east_name = 'easting'\n",
    "        #north_name = 'northing'\n",
    "        id = index\n",
    "        sat = row['satellite']\n",
    "        location = i\n",
    "\n",
    "        sow_df = raster_to_csv(raster_file, quality_file,\n",
    "                                #east_name, north_name, zone_number,\n",
    "                                output_joined, id, sat, location, season)\n",
    "        if i == 'mm':\n",
    "            list_mm.append(sow_df)\n",
    "        elif i == 'nn':\n",
    "            list_nn.append(sow_df)\n",
    "        elif i == 'ms':\n",
    "            list_ms.append(sow_df)\n",
    "        elif i == 'mn':\n",
    "            list_mn.append(sow_df)\n",
    "        elif i == 'ss':\n",
    "            list_ss.append(sow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(list_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############################\n",
    "## EVALUATE SCENE QUALITY ##\n",
    "############################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "starting_year = 1984\n",
    "ending_year = 2023\n",
    "years_range = np.arange(starting_year, ending_year + 1).tolist()\n",
    "\n",
    "full_list = {'ss': list_ss, 'ms': list_ms, 'mm': list_mm, 'mn': list_mn, 'nn': list_nn}\n",
    "#list_sow = {'ss': sow_list_ss, 'ms': sow_list_ms, 'mm': sow_list_mm, 'mn': sow_list_mn, 'nn': sow_list_nn}\n",
    "\n",
    "max_unique_length = 0\n",
    "best_list_name = None\n",
    "for name, list in full_list.items():\n",
    "    # making the basic dataframe out of each list\n",
    "    result_df = pd.concat(list, axis=0)\n",
    "    result_df['year'] = result_df['date'].str[0:4]#.astype(int)\n",
    "    result_df['month'] = result_df['date'].str[4:6]\n",
    "    result_df['day'] = result_df['date'].str[6:8]\n",
    "    result_df['date'] = pd.to_datetime(result_df['date'], format='%Y%m%d')\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "    for index, row in result_df.iterrows():\n",
    "        year = row['year']\n",
    "        if row['season'] == 'gro':\n",
    "            result_df.at[index,'target_date'] = pd.to_datetime(f'{year}{growing_mid_month}{growing_mid_day}',format='%Y%m%d')\n",
    "            #print(result_df.at[index,'target_date'])\n",
    "        elif row['season'] == 'sow':\n",
    "            result_df.at[index,'target_date'] = pd.to_datetime(f'{year}{planting_mid_month}{planting_mid_day}', format='%Y%m%d')\n",
    "        else:\n",
    "            continue\n",
    "    #result_df['target_date'] = pd.to_datetime(result_df['target_date'])\n",
    "    result_df['date'] = pd.to_datetime(result_df['date'])\n",
    "    result_df['days_from_target'] = (result_df['target_date'] - result_df['date']).dt.days.abs()\n",
    "    #result_df['days_from_target'] = result_df['days_from_target'].abs()\n",
    "    #result_df.drop(columns=['target_date'], inplace=True)\n",
    "    result_df['indicator'] = \"\"\n",
    "    # evaluating quality by first categorizing as good or bad\n",
    "    good = [5440, 21824, 5442, 21826, 5504, 21888, 5506, 21890, 5760, 22144, 7824, 24472, 24216, 8088]\n",
    "    result_df['indicator'] = np.where(result_df['quality'].isin(good), 1, 0)\n",
    "    result_df['qual_x_ind'] = result_df['indicator'] * result_df['count']\n",
    "    result_df['qual_x_ind_sum'] = result_df.groupby(['date', 'satellite'])['qual_x_ind'].transform('sum')\n",
    "    result_df['year_good_gro'] = np.where((result_df['qual_x_ind_sum'] >= 128000) & (result_df['season'] == 'gro'), result_df['year'], np.nan)\n",
    "    result_df['year_good_sow'] = np.where((result_df['qual_x_ind_sum'] >= 128000) & (result_df['season'] == 'sow'), result_df['year'], np.nan)\n",
    "    unique_gro = result_df['year_good_gro'].unique().tolist()\n",
    "    unique_sow = result_df['year_good_sow'].unique().tolist()\n",
    "    series_gro = pd.Series(unique_gro)\n",
    "    series_gro = series_gro.dropna()\n",
    "    series_gro = series_gro.astype(float)\n",
    "    gro_list = series_gro.tolist()\n",
    "    gro_list = [int(element) for element in gro_list]\n",
    "    series_sow = pd.Series(unique_sow)\n",
    "    series_sow = series_sow.dropna()\n",
    "    series_sow = series_sow.astype(float)\n",
    "    sow_list = series_sow.tolist()\n",
    "    sow_list = [int(element) for element in sow_list]\n",
    "    int_list= [value for value in sow_list if value in gro_list]\n",
    "    int_set = set(gro_list) & set(sow_list)\n",
    "    # if len(unique_list) > max_unique_length:\n",
    "    #     max_unique_length = len(unique_list)\n",
    "    #     best_list_name = name\n",
    "    missing_elements = [year for year in years_range if year not in int_list]\n",
    "    result_df['year_in_both_seasons'] = np.where(result_df['year'].astype(int).isin(int_set), 1, np.nan)\n",
    "    print(f'For {name}, from {starting_year} to {ending_year}, there are {len(int_list)} years available with low cloud cover.')\n",
    "    #print(f'Included years: {sorted(unique_list)}')\n",
    "    print(f'Missing years for {name}: {sorted(missing_elements)}')\n",
    "    # writing the csvs\n",
    "    qual_folder = f'{wd}{path}_{row_name}_qual'\n",
    "    os.makedirs(qual_folder, exist_ok=True)\n",
    "    qual_out = os.path.join(wd, qual_folder, f'{path}_{row_name}_quality_{name}_full.csv')\n",
    "    result_df.to_csv(qual_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "##### PICK BEST SCENE #####\n",
    "###########################\n",
    "best_bb = 'nn'\n",
    "best_path = os.path.join(qual_folder, f'{path}_{row_name}_quality_{best_bb}_full.csv')\n",
    "best_df = pd.read_csv(best_path)\n",
    "best_df = best_df.dropna(subset=['year_good_sow', 'year_good_gro'], how='all')\n",
    "best_df = best_df.dropna(subset=['year_in_both_seasons'])\n",
    "best_df['min_days_from_target'] = best_df.groupby(['year', 'season'])['days_from_target'].transform('min')\n",
    "best_df = best_df[best_df['days_from_target'] <= best_df['min_days_from_target']]\n",
    "unique_evi = best_df['trim_file_evi'].unique().tolist()\n",
    "unique_qual = best_df['trim_file_qual'].unique().tolist()\n",
    "unique_scenes = unique_evi + unique_qual\n",
    "best_df = best_df.drop(columns=['min_days_from_target', 'year_in_both_seasons'])\n",
    "#print(best_df.head(10))\n",
    "#print(unique_scenes)\n",
    "best_df.to_csv(os.path.join(qual_folder,f'{path}_{row_name}_{best_bb}_selected.csv'), index = False)\n",
    "\n",
    "def save_list_to_txt(lst, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for item in lst:\n",
    "            file.write(str(item) + '\\n')\n",
    "\n",
    "# Save the list to a .txt file\n",
    "save_list_to_txt(unique_qual, os.path.join(qual_folder,f'{path}_{row_name}_{best_bb}_quality_scenes.txt'))\n",
    "save_list_to_txt(unique_evi, os.path.join(qual_folder,f'{path}_{row_name}_{best_bb}_evi_scenes.txt'))\n",
    "save_list_to_txt(unique_scenes, os.path.join(qual_folder,f'{path}_{row_name}_{best_bb}_all_scenes.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
