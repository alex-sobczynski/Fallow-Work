{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from api import M2M\n",
    "\n",
    "m2m = M2M('sobczynski','Fallow4Sure!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############################\n",
    "## GET LOCATION OF CENTER ##\n",
    "############################\n",
    "wd = \"C:/Users/asobc/PycharmProjects/fallow/\"\n",
    "wrs_ref = pd.read_excel(f'{wd}WRScornerPoints_0.xlsx')\n",
    "path = 170\n",
    "row_name = 64\n",
    "path_row = \"170064\"\n",
    "row_index = wrs_ref[(wrs_ref['PATH'] == path) & (wrs_ref['ROW'] == row_name)].index[0]\n",
    "\n",
    "center_lat = wrs_ref.at[row_index, 'CTR LAT']\n",
    "center_lon = wrs_ref.at[row_index, 'CTR LON']\n",
    "print(center_lon)\n",
    "print(center_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "##### COMPILE ALL IDS #####\n",
    "###########################\n",
    "\n",
    "# Get rid of Tier 2 and scenes and scenes with lots of cloud cover\n",
    "scene_list = []\n",
    "first_year = 1984\n",
    "last_year = 2023\n",
    "planting_start_month = '02'\n",
    "planting_start_day = '01'\n",
    "planting_end_month = '03'\n",
    "planting_end_day = '31'\n",
    "growing_start_month = '04'\n",
    "growing_start_day = '01'\n",
    "growing_end_month = '06'\n",
    "growing_end_day = '30'\n",
    "target_grow_month = \"06\"\n",
    "target_grow_day = \"15\"\n",
    "target_plant_month = \"02\"\n",
    "target_plant_day = \"15\"\n",
    "\n",
    "for year in range(first_year, 2013):\n",
    "    params = {\n",
    "        \"datasetName\": 'landsat_tm_c2_l2',\n",
    "        \"startDate\": f\"{year}-{planting_start_month}-{planting_start_day}\",\n",
    "        \"endDate\": f\"{year}-{growing_end_month}-{growing_end_day}\",\n",
    "        \"geoJsonType\": \"Polygon\",\n",
    "        \"geoJsonCoords\": [[[center_lon, center_lat],\n",
    "                           [center_lon, (center_lat - .25)],\n",
    "                           [(center_lon + .25), (center_lat - .25)],\n",
    "                           [(center_lon + .25), center_lat],\n",
    "                           [center_lon, center_lat]]],\n",
    "        \"maxCC\": 70,\n",
    "        \"maxResults\": 10000\n",
    "    }\n",
    "    scenes = m2m.searchScenes(**params)\n",
    "    for result in scenes['results']:\n",
    "        entityId = result['displayId']\n",
    "        scene_list.append(entityId)\n",
    "\n",
    "for year in range(1999, last_year + 1):\n",
    "    params = {\n",
    "        \"datasetName\": 'landsat_etm_c2_l2',\n",
    "        \"startDate\": f\"{year}-{planting_start_month}-{planting_start_day}\",\n",
    "        \"endDate\": f\"{year}-{growing_end_month}-{growing_end_day}\",\n",
    "        \"geoJsonType\": \"Polygon\",\n",
    "        \"geoJsonCoords\": [[[center_lon, center_lat],\n",
    "                           [center_lon, (center_lat - .25)],\n",
    "                           [(center_lon + .25), (center_lat - .25)],\n",
    "                           [(center_lon + .25), center_lat],\n",
    "                           [center_lon, center_lat]]],\n",
    "        \"maxCC\": 70,\n",
    "        \"maxResults\": 10000\n",
    "    }\n",
    "    scenes = m2m.searchScenes(**params)\n",
    "    for result in scenes['results']:\n",
    "        entityId = result['displayId']\n",
    "        scene_list.append(entityId)\n",
    "\n",
    "for year in range(2013, last_year + 1):\n",
    "    params = {\n",
    "        \"datasetName\": 'landsat_ot_c2_l2',\n",
    "        \"startDate\": f\"{year}-{planting_start_month}-{planting_start_day}\",\n",
    "        \"endDate\": f\"{year}-{growing_end_month}-{growing_end_day}\",\n",
    "        \"geoJsonType\": \"Polygon\",\n",
    "        \"geoJsonCoords\": [[[center_lon, center_lat],\n",
    "                           [center_lon, (center_lat - .25)],\n",
    "                           [(center_lon + .25), (center_lat - .25)],\n",
    "                           [(center_lon + .25), center_lat],\n",
    "                           [center_lon, center_lat]]],\n",
    "        \"maxCC\": 70,\n",
    "        \"maxResults\": 10000\n",
    "    }\n",
    "    scenes = m2m.searchScenes(**params)\n",
    "    for result in scenes['results']:\n",
    "        entityId = result['displayId']\n",
    "        scene_list.append(entityId)\n",
    "\n",
    "scene_list[:] = [scene for scene in scene_list if not scene.endswith('T2') and path_row in scene]\n",
    "\n",
    "#print(scene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#### DATAFRAME OF SCENE INFO ####\n",
    "#################################\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# make a dataframe that is id, year, month, day, distance from central date\n",
    "scene_df = pd.DataFrame({'scene_id': scene_list})\n",
    "\n",
    "scene_df['year'] = \"\"\n",
    "scene_df['month'] = \"\"\n",
    "scene_df['day'] = \"\"\n",
    "scene_df['season'] = \"\"\n",
    "scene_df['target_date'] = \"\"\n",
    "\n",
    "for index, row in scene_df.iterrows():\n",
    "    scene_id = row['scene_id']\n",
    "    year = scene_id[17:21]\n",
    "    month = scene_id[21:23]\n",
    "    day = scene_id[23:25]\n",
    "    scene_df.at[index,'year'] = year\n",
    "    scene_df.at[index,'month'] = month\n",
    "    scene_df.at[index,'day'] = day\n",
    "\n",
    "scene_df['date'] = pd.to_datetime(scene_df[['day', 'month', 'year']], format='%Y-%m-%d').dt.date\n",
    "plant_end = pd.to_datetime(scene_df['year'].astype(str) + f'-{planting_end_month}-{planting_end_day}', format='%Y-%m-%d').dt.date\n",
    "plant_target = pd.to_datetime(scene_df['year'].astype(str) + f'-{target_plant_month}-{target_plant_day}', format='%Y-%m-%d').dt.date\n",
    "grow_target = pd.to_datetime(scene_df['year'].astype(str) + f'-{target_grow_month}-{target_grow_day}', format='%Y-%m-%d').dt.date\n",
    "\n",
    "scene_df.loc[scene_df['date'] <= plant_end, 'season'] = 'sow'\n",
    "scene_df.loc[scene_df['date'] <= plant_end, 'target_date'] = plant_target\n",
    "scene_df.loc[scene_df['date'] > plant_end, 'season'] = 'gro'\n",
    "scene_df.loc[scene_df['date'] > plant_end, 'target_date'] = grow_target\n",
    "\n",
    "scene_df['target_date'] = pd.to_datetime(scene_df['target_date'])\n",
    "scene_df['date'] = pd.to_datetime(scene_df['date'])\n",
    "\n",
    "scene_df['days_from_target'] = (scene_df['target_date'] - scene_df['date']).dt.days.abs()\n",
    "scene_df.drop(columns=['target_date'], inplace=True)\n",
    "\n",
    "print(scene_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# TRIM TO THREE RELEVANT SCENES #\n",
    "#################################\n",
    "\n",
    "scene_df['year_season'] = scene_df['year'].astype(str) + '_' + scene_df['season']\n",
    "grouped = scene_df.groupby(scene_df['year_season'])\n",
    "#grouped = scene_df.groupby(['year', 'season']).size().unstack(fill_value=0)\n",
    "def filter_func(x):\n",
    "    if len(x) > 3:\n",
    "        sorted_group = x.sort_values(by='days_from_target', ascending=True)\n",
    "        return sorted_group.iloc[:3]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "three_df = grouped.apply(filter_func)\n",
    "three_df = three_df.reset_index(drop=True)\n",
    "print(three_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "################################\n",
    "###### ENSURE SOW AND GRO ######\n",
    "################################\n",
    "\n",
    "group_both = scene_df.groupby(['year', 'season']).size().unstack(fill_value=0)\n",
    "good_years = group_both[(group_both['sow'] > 0) & (group_both['gro'] > 0)]\n",
    "covered = good_years.index.tolist()\n",
    "\n",
    "three_df_2 = three_df[three_df['year'].isin(covered)]\n",
    "print(len(three_df_2['scene_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#### TEXT FILE FOR REFERENCE ####\n",
    "#################################\n",
    "\n",
    "import os\n",
    "\n",
    "def save_list_to_txt(lst, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for item in lst:\n",
    "            file.write(str(item) + '\\n')\n",
    "\n",
    "# Save the list to a .txt file\n",
    "save_list_to_txt(three_df_2['scene_id'].tolist(), os.path.join(wd,f'{path}_{row_name}_scenes.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "##### INITIALIZE ESPA API #####\n",
    "###############################\n",
    "# from here: https://espa.cr.usgs.gov/static/docs/examples/api_demo.py\n",
    "import platform\n",
    "import requests\n",
    "import json\n",
    "import getpass\n",
    "\n",
    "host = 'https://espa.cr.usgs.gov/api/v1/'\n",
    "username = 'sobczynski'\n",
    "password = 'Fallow4Sure!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "#### FUNCTION TO INTERACT ####\n",
    "##############################\n",
    "\n",
    "def espa_api(endpoint, verb='get', body=None, uauth=None):\n",
    "    \"\"\" Suggested simple way to interact with the ESPA JSON REST API \"\"\"\n",
    "    auth_tup = uauth if uauth else (username, password)\n",
    "    response = getattr(requests, verb)(host + endpoint, auth=auth_tup, json=body)\n",
    "    print('{} {}'.format(response.status_code, response.reason))\n",
    "    data = response.json()\n",
    "    if isinstance(data, dict):\n",
    "        messages = data.pop(\"messages\", None)\n",
    "        if messages:\n",
    "            print((json.dumps(messages, indent=4)))\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# Check that the user is available\n",
    "online = espa_api('user')\n",
    "print((json.dumps(online, indent=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "## SUMMARIZE AVAILABLE PRODUCTS ##\n",
    "##################################\n",
    "\n",
    "scene_list = three_df_2['scene_id'].tolist()\n",
    "avail_list = {'inputs': scene_list}\n",
    "\n",
    "resp = espa_api('available-products', body=avail_list)\n",
    "#print(json.dumps(resp, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "##### SPECIFY ORDER #####\n",
    "#########################\n",
    "\n",
    "order = espa_api('available-products', body=dict(inputs=scene_list))\n",
    "# I am not deviating from the utm projection, but could\n",
    "for sensor in order.keys():\n",
    "    order[sensor]['products'] = ['sr_evi']\n",
    "order['format'] = 'gtiff'\n",
    "order['resampling_method'] = 'nn' # nearest neighbor. Other options are cc (cubic convolution) and bil (bilinear interpolation)\n",
    "order['note'] = 'test download tanzania'\n",
    "print((json.dumps(order, indent=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "##### PLACE ORDER #####\n",
    "#######################\n",
    "\n",
    "from IPython.display import display, Javascript\n",
    "\n",
    "def confirm_execute():\n",
    "    display(Javascript('IPython.notebook.execute_cell()'))\n",
    "\n",
    "confirmation = input(f\"Do you want to order scenes for path: {path} and row: {row_name}? (yes/no)\")\n",
    "\n",
    "if confirmation.lower() == \"yes\":\n",
    "    confirm_execute()\n",
    "else:\n",
    "    print(\"Code execution aborted.\")\n",
    "    raise SystemExit(\"User aborted execution\")\n",
    "\n",
    "place = espa_api('order', verb='post', body=order)\n",
    "print((json.dumps(place, indent=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########################\n",
    "##### CHECK STATUS #####\n",
    "########################\n",
    "\n",
    "orderid = place['orderid']\n",
    "check = espa_api('order-status/{}'.format(orderid))\n",
    "print((json.dumps(check, indent=4)))\n",
    "\n",
    "done = espa_api('item-status/{0}'.format(orderid), body={'status': 'complete'})\n",
    "#print((json.dumps(done[orderid], indent=4)))\n",
    "num_items = len(done[orderid])\n",
    "total_items = len(three_df_2['scene_id'])\n",
    "print(f\"{num_items} of {total_items} are processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############################\n",
    "### WRITE DOWNLOAD FILES ###\n",
    "############################\n",
    "\n",
    "urls = [item.get('product_dload_url') for item in done[orderid]]\n",
    "save_list_to_txt(urls, f\"D:/{path_row}_raw/{path_row}.txt\")\n",
    "bat_content = f'for /F \"tokens=*\" %%a in ({path_row}.txt) do curl -O %%a'\n",
    "with open(f'D:/{path_row}_raw/{path_row}.bat', 'w') as bat_file:\n",
    "    bat_file.write(bat_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
